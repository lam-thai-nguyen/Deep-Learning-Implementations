# Deep Learning Implementations

keywords: **pytorch** | **deep learning** | **neural networks**

who is this repo. for: people who (1) have basic understandings of ML, DL, (2) are familiar with ML, DL techniques' names, (3) want to implement from scratch and implement using pytorch, (4) want to get the hang of pytorch üêç and (5) are learning or have finished MLS/DLS by Andrew Ng.

status: **ongoing**

paper by topic:

- **Batch Normalization ([BatchNorm](BatchNorm.py))**: Ioffe, S., & Szegedy, C. (2015, June). Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning (pp. 448-456). pmlr.
- **Dropout ([Dropout](Dropout.py))**: Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1), 1929-1958.
- **He Initialization ([He Initialization](He_Initialization.py))**: He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision (pp. 1026-1034).